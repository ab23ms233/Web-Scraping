{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c6125d",
   "metadata": {},
   "source": [
    "Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea4e74d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'else' statement on line 352 (Class_Scraping.py, line 354)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92mc:\\Users\\ARYA BASAK\\miniconda3\\envs\\web_scraping\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3667\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfrom Class_Scraping import QuoteScraping, BookScraping\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ARYA BASAK\\OneDrive\\Documents\\Programming\\PYTHON\\GitHub Projects\\Web Scraping\\Class_Scraping.py:354\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef scrape_all_quotes(self) -> Dict[str, Dict[str, List[str]]]:\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'else' statement on line 352\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from Class_Scraping import QuoteScraping, BookScraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8a285",
   "metadata": {},
   "source": [
    "SCRAPING QUOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0a55a",
   "metadata": {},
   "source": [
    "Initialising variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e32445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://quotes.toscrape.com/\"   \n",
    "url = base_url\n",
    "header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"}      # Chrome browser string\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a034dab",
   "metadata": {},
   "source": [
    "Scraping a single page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97755383",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = soup.find_all(\"div\", class_=\"quote\")\n",
    "\n",
    "for quote in quotes:\n",
    "    text = quote.find(\"span\", class_=\"text\").get_text(strip=True)\n",
    "    author = quote.find(\"small\", class_=\"author\").get_text(strip=True)\n",
    "    tags = [tag.get_text(strip=True) for tag in quote.find_all(\"a\", class_=\"tag\")]\n",
    "\n",
    "    for tag in tags:\n",
    "        data[author][tag].append(text)\n",
    "\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a012d3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/page/2/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_button = soup.find(\"li\", class_=\"next\")\n",
    "next_href = next_button.find(\"a\")\n",
    "next_href[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_scraper = QuoteScraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_scraper.scrape_author_quotes(\"albert einstein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_scraper.scrape_author_info(\"albert einstein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_scraper.scrape_all_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1813ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_scraper.scrape_all_quotes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfefc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_scraper = BookScraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_scraper.genre_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b55a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_scraper.scrape_books_from_genre(\"romance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_scraper.scrape_all_books()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_scraper.scrape_book_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a196c3c",
   "metadata": {},
   "source": [
    "Scraping Multiple Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b53824",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(lambda: defaultdict(list))       # Quote data is stored here\n",
    "author_details = defaultdict()      # Author details are stored here\n",
    "page_count = 0\n",
    "\n",
    "while url:\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5, headers=header)     # Getting response from website\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    quotes = soup.find_all(\"div\", class_=\"quote\")       # Find all quotes in 1 page\n",
    "    \n",
    "    page_count += 1\n",
    "    print(page_count)\n",
    "\n",
    "    for quote in quotes:\n",
    "        text = quote.find(\"span\", class_=\"text\").get_text(strip=True)       # quote_text\n",
    "        author = quote.find(\"small\", class_=\"author\").get_text(strip=True)      # author\n",
    "        tags = [tag.get_text(strip=True) for tag in quote.find_all(\"a\", class_=\"tag\")]      # tags associated with the quote\n",
    "\n",
    "        for tag in tags:\n",
    "            data[author][tag].append(text)      # Listing all quotes by author and tag\n",
    "\n",
    "        if author not in author_details:        # Scraping author details if not scraped\n",
    "            print(author)\n",
    "            about_href = quote.find(\"a\")[\"href\"]\n",
    "            author_url = base_url + about_href\n",
    "\n",
    "            author_response = requests.get(author_url)\n",
    "            author_soup = BeautifulSoup(author_response.text, \"html.parser\")\n",
    "\n",
    "            born_date = author_soup.find(\"span\", class_=\"author-born-date\").get_text(strip=True)\n",
    "            born_location = author_soup.find(\"span\", class_=\"author-born-location\").get_text(strip=True)[3:]\n",
    "\n",
    "            author_details[author] = {\"Born On\": born_date, \"Location\": born_location}\n",
    "            time.sleep(random.uniform(1, 3))        # Delay requests to reduce traffic on website\n",
    "            \n",
    "    next_button = soup.find(\"li\", class_=\"next\")        # Next button at the end of page for author_details\n",
    "\n",
    "    if next_button:     # If next_buuton is availbale\n",
    "        next_href = next_button.find(\"a\")[\"href\"]\n",
    "        url = base_url + next_href      # url for next page\n",
    "    else:\n",
    "        url = None\n",
    "    \n",
    "    print()\n",
    "    time.sleep(random.uniform(1, 3))        # Delay requests to reduce traffic on website for next_page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a579cccd",
   "metadata": {},
   "source": [
    "Writing data to JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c1fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"quotes.json\", mode=\"w\", encoding='utf-8') as q:\n",
    "    json.dump(data,  q, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(\"author_details.json\", mode=\"w\", encoding='utf-8') as a:\n",
    "    json.dump(author_details, a, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ef96c",
   "metadata": {},
   "source": [
    "SCRAPING BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f21287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://books.toscrape.com/\"\n",
    "header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"}      # Chrome browser string\n",
    "response = requests.get(base_url, timeout=5, headers=header)\n",
    "print(response.status_code)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "side_panel = soup.find(\"ul\", class_=\"nav nav-list\")\n",
    "genres = side_panel.select(\"ul ul li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e3d6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books_from_genre(genre_url):\n",
    "    global rating_map, page_count, book_data\n",
    "    base_genre_url = genre_url\n",
    "\n",
    "    # Scraping a Genre\n",
    "    while genre_url:\n",
    "        page_count += 1\n",
    "        print(page_count)\n",
    "\n",
    "        genre_response = requests.get(genre_url, timeout=5, headers=header)\n",
    "        genre_soup = BeautifulSoup(genre_response.text, \"html.parser\")\n",
    "\n",
    "        # All the books in the current page of the genre\n",
    "        books = genre_soup.select(\"article.product_pod\")\n",
    "\n",
    "        # Scraping details of each book\n",
    "        for book in books:\n",
    "            price = book.select_one(\"p.price_color\").get_text(strip=True)       # price\n",
    "            rating_text = book.select_one(\"p.star-rating\")[\"class\"][-1].lower()\n",
    "            rating = rating_map[rating_text]        # rating\n",
    "\n",
    "            # Scraping details from individual book pages\n",
    "            book_href = book.h3.select_one(\"a\")[\"href\"]\n",
    "            book_url = base_url + \"catalogue/\" + book_href[9:]\n",
    "            book_response = requests.get(book_url, timeout=5, headers=header)\n",
    "            book_soup = BeautifulSoup(book_response.text, \"html.parser\")\n",
    "\n",
    "            title = book_soup.h1.get_text(strip=True)       # title\n",
    "            print(title)\n",
    "            availability = book_soup.find(\"p\", class_=\"instock availability\").get_text(strip=True)      # availability\n",
    "            table = book_soup.find(\"table\", class_=\"table table-striped\")\n",
    "            rows = table.select(\"tr\")\n",
    "\n",
    "            for row in rows:\n",
    "                if row.select_one(\"th\").get_text(strip=True) == 'UPC':\n",
    "                    upc = row.select_one(\"td\").get_text(strip=True)     # UPC\n",
    "\n",
    "            book_data[genre_text][title] = {\"UPC\": upc, \"Price\": price, \"Rating\": rating, \"Availability\": availability}     # Recording data\n",
    "            # time.sleep(random.uniform(1,2))\n",
    "\n",
    "        # Looking for next button in the same genre\n",
    "        next_button = genre_soup.find(\"li\", class_=\"next\")\n",
    "        print()\n",
    "\n",
    "        if next_button:\n",
    "            next_href = next_button.find(\"a\")[\"href\"]\n",
    "            genre_url = base_genre_url.replace(\"index.html\", next_href)\n",
    "            # time.sleep(random.uniform(1, 2))\n",
    "        else:\n",
    "            page_count = 0\n",
    "            print()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b13541",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_count = 0\n",
    "rating_map = {\"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5}\n",
    "book_data = defaultdict(lambda: defaultdict())\n",
    "\n",
    "for genre in genres:\n",
    "    genre_text = genre.get_text(strip=True)\n",
    "    genre_href = genre.find(\"a\")[\"href\"]\n",
    "    print(genre_text)\n",
    "\n",
    "    genre_url = base_url + genre_href\n",
    "    scrape_books_from_genre(genre_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5b7c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://books.toscrape.com/catalogue/category/books/mystery_3/index.html\n"
     ]
    }
   ],
   "source": [
    "genre = genres[1]\n",
    "\n",
    "genre_href = genre.find(\"a\")[\"href\"]\n",
    "genre_url = base_url + genre_href\n",
    "print(genre_url)\n",
    "\n",
    "genre_response = requests.get(genre_url, timeout=5, headers=header)\n",
    "genre_soup = BeautifulSoup(genre_response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dd906f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://books.toscrape.com/catalogue/sharp-objects_997/index.html'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = genre_soup.select(\"article.product_pod\")\n",
    "book = books[0]\n",
    "book_href = book.h3.select_one(\"a\")[\"href\"]\n",
    "book_url = base_url + \"catalogue/\" + book_href[9:]\n",
    "book_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e6973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"next\"><a href=\"page-2.html\">next</a></li>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://books.toscrape.com/catalogue/category/books/mystery_3/page-2.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_button = genre_soup.find(\"li\", class_=\"next\")\n",
    "print(next_button)\n",
    "next_href = next_button.find(\"a\")[\"href\"]\n",
    "genre_url = genre_url.replace(\"index.html\", next_href)\n",
    "genre_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f8a6bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['star-rating', 'Two']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = book.select_one(\"p.star-rating\")\n",
    "rating[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f50d89c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n  \\n\\n\\n    It\\'s Only the Himalayas | Books to Scrape - Sandbox\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBooks to Scrape We love being scraped!\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\n\\n\\nBooks\\n\\n\\nTravel\\n\\nIt\\'s Only the Himalayas\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIt\\'s Only the Himalayas\\nÂ£45.17\\n\\n\\n    \\n        In stock (19 available)\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\xa0\\n\\n\\n\\n\\nWarning! This is a demo website for web scraping purposes. Prices and ratings here were randomly assigned and have no real meaning.\\n\\n\\n\\nProduct Description\\n\\nâ\\x80\\x9cWherever you go, whatever you do, just . . . donâ\\x80\\x99t do anything stupid.â\\x80\\x9d â\\x80\\x94My MotherDuring her yearlong adventure backpacking from South Africa to Singapore, S. Bedford definitely did a few things her mother might classify as \"stupid.\" She swam with great white sharks in South Africa, ran from lions in Zimbabwe, climbed a Himalayan mountain without training in Nepal, and wa â\\x80\\x9cWherever you go, whatever you do, just . . . donâ\\x80\\x99t do anything stupid.â\\x80\\x9d â\\x80\\x94My MotherDuring her yearlong adventure backpacking from South Africa to Singapore, S. Bedford definitely did a few things her mother might classify as \"stupid.\" She swam with great white sharks in South Africa, ran from lions in Zimbabwe, climbed a Himalayan mountain without training in Nepal, and watched as her friend was attacked by a monkey in Indonesia.But interspersed in those slightly more crazy moments, Sue Bedfored and her friend \"Sara the Stoic\" experienced the sights, sounds, life, and culture of fifteen countries. Joined along the way by a few friends and their aging fathers here and there, Sue and Sara experience the trip of a lifetime. They fall in love with the world, cultivate an appreciation for home, and discover who, or what, they want to become.It\\'s Only the Himalayas is the incredibly funny, sometimes outlandish, always entertaining confession of a young backpacker that will inspire you to take your own adventure. ...more\\n\\nProduct Information\\n\\n\\n\\nUPCa22124811bfa8350\\n\\n\\nProduct TypeBooks\\n\\n\\nPrice (excl. tax)Â£45.17\\n\\n\\nPrice (incl. tax)Â£45.17\\n\\n\\nTaxÂ£0.00\\n\\n\\nAvailability\\nIn stock (19 available)\\n\\n\\nNumber of reviews\\n0\\n\\n\\n\\n\\n\\n\\n\\nProducts you recently viewed\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLibertarianism for Beginners\\n\\nÂ£51.33\\n\\n\\n    \\n        In stock\\n    \\n\\n\\nAdd to basket\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMesaerion: The Best Science ...\\n\\nÂ£37.59\\n\\n\\n    \\n        In stock\\n    \\n\\n\\nAdd to basket\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOlio\\n\\nÂ£23.88\\n\\n\\n    \\n        In stock\\n    \\n\\n\\nAdd to basket\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOur Band Could Be ...\\n\\nÂ£57.25\\n\\n\\n    \\n        In stock\\n    \\n\\n\\nAdd to basket\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRip it Up and ...\\n\\nÂ£35.02\\n\\n\\n    \\n        In stock\\n    \\n\\n\\nAdd to basket\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nScott Pilgrim\\'s Precious Little ...\\n\\nÂ£52.29\\n\\n\\n    \\n        In stock\\n    \\n\\n\\nAdd to basket\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_href = book.h3.select_one(\"a\")[\"href\"]\n",
    "book_url = base_url + \"catalogue/\" + book_href[9:]\n",
    "print(book_url)\n",
    "book_response = requests.get(book_url, timeout=5, headers=header)\n",
    "book_soup = BeautifulSoup(book_response.text, \"html.parser\")\n",
    "\n",
    "book_soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8e86c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPC'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = book_soup.select_one(\"table.table.table-striped\")\n",
    "rows = table.select(\"tr\")\n",
    "row = rows[0]\n",
    "row.select_one(\"th\").get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a252f75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "i = \"jk rowling\"\n",
    "c = \"j.k. rowling\"\n",
    "similarity = difflib.SequenceMatcher(None, i, c).ratio()\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca3ce8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
